---
title: 爬虫对比
tags: 新建,模板,小书匠
grammar_cjkRuby: true
---


Larbin是一个开源的网络爬虫工具，由法国的年轻人 Sébastien Ailleret 独立开发。Larbin目的是能够跟踪页面的URL进行扩展的抓取，最后为搜索引擎提供广泛的数据来源。
Larbin只是一个爬虫，也就是说Larbin只实现抓取网页功能，至于如何解析的事情则由用户自己完成，另外，如何存储到数据库以及建立索引的事情 Larbin也不提供。
Latbin最初的设计也是依据设计简单但是高度可配置性的原则，一个简单的Larbin的爬虫可以每天获取500万的网页，非常高效。   
功能

Larbin 指定入口URL后，可以自动扩展，甚至整个网站镜像。
Larbin 支持通过后缀名对抓取网页进行过滤，比如图片类的可以不抓取：.png .jpg .jpeg .bmp .smi .tiff .gif 。
Larbin 只保存原始网页，可以作为通用搜索引擎的信息的来源。
支持的配置选项：抓取深度、间隔、并发度、代理。
问题 

仅提供保存网页抓取功能，没有进行进一步的网页解析；
不支持分布式系统，抓取和存储；
功能相对简单，提供的配置项也不够多；
不支持网页自动重访，更新功能；
从2003年底以后，Labin已经放弃更新，目前处于荒芜长草的状态。
Nutch

开发语言：Java
Site: http://lucene.apache.org/nutch/
简介

Apache的子项目之一，属于Lucene项目下的子项目。
Nutch是一个类似Google通用搜索引擎的解决方案，基于Hadoop任务的分布式处理模型保证了系统的性能，类似Eclipse的插件机制保证了系统的可客户化，而且很容易集成到自己的应用之中。 
总体上Nutch可以分为2个部分：抓取部分和搜索部分。抓取程序抓取页面并把抓取回来的数据做成反向索引，搜索程序则对反向索引搜索回答用户的请求。抓取程序和搜索程序的接口是索引，两者都使用索引中的字段。抓取程序和搜索程序可以分别位于不同的机器上，下面详细介绍一下抓取部分。
抓取过程

     
    抓取是一个循环的过程：抓取工具从WebDB中生成了一个 fetchlist 集合；抓取工具根据fetchlist从网络上下载网页内容；解析工具发现的新链接更新WebDB；然后再生成新的fetchlist；周而复始。这个抓取循环在nutch中经常指： generate/fetch/parse/update 循环。
    一般来说同一域名下的 url 链接会被合成到同一个 fetchlist。这样做的考虑是：当同时使用多个工具抓取的时候，不会产生重复抓取的现象。Nutch 遵循 Robots Exclusion Protocol, 可以用robots.txt 定义保护私有网页数据不被抓去。
    上面这个抓取工具的组合是Nutch的最外层的，也可以直接使用更底层的工具，自己组合这些底层工具的执行顺序达到同样的结果。这是Nutch吸引人的地方。下面把上述过程分别详述一下，括号内就是底层工具的名字：
把开始抓取的跟Url 放入WebDb (inject)。
从WebDb的新 segment 中生成 fetchlist (generate)。
根据 fetchlist 列表抓取网页的内容 (fetch)。
根据抓取回来的网页链接url
更新 WebDB (updatedb)。
重复上面2-5个步骤直到到达指定的抓取层数。
功能 

基于Hadoop的分布式系统；
存储层剥离，支持存储HBase, Cassandra, MySql等数据库
基于插件式设计，扩展和定制比较方便
支持网页解析和索引，可以对接至Solr，搭建通用的搜索引擎
缺点

 基于Hadoop开发，Windows下开发调试比较麻烦


Heritrix
开发语言：Java
Site: https://webarchive.jira.com/wiki/display/Heritrix/Heritrix 
简介

Heritrix是一个开源，可扩展的web爬虫项目。Heritrix设计成严格按照robots.txt文件的排除指示和META robots标签。
与Nutch对比

Heritrix 是 SourceForge上的开源产品，Nutch为Apache的一个子项目，它们实现的原理基本一致：深度遍历网站的资源(Nutch应该属于广度优先遍历)，将这些资源抓取到本地，使用的方法都是分析网站每一个有效的URL，并提交Http请求，从而获得相应结果，生成本地文件及相应的日志信息等。
Heritrix 是个 "Archival crawler" -- 用来获取完整的、精确的、站点内容的深度复制。包括获取图像以及其他非文本内容。抓取并存储相关的内容。对内容来者不拒，不对页面进行内容上的修改。重新爬行对相同的URL不针对先前的进行替换。爬虫通过Web用户界面启动、监控、调整，允许弹性的定义要获取的URL。
Nutch和Heritrix的差异

Nutch 只获取并保存可索引的内容；Heritrix 则是照单全收，力求保存页面原貌
Nutch 可以修剪内容，或者对内容格式进行转换。
Nutch 保存内容为数据库优化格式便于以后索引；刷新替换旧的内容。而Heritrix 是添加(追加)新的内容。
Nutch 从命令行运行、控制。Heritrix 有 Web 控制管理界面。
Nutch 的定制通过插件扩展实现，Heritrix 可控制的参数更多。
Heritrix提供的功能没有nutch多，有点整站下载的味道。既没有索引又没有解析，甚至对于重复爬取URL都处理不是很好。
Heritrix的功能强大 但是配置起来却有点麻烦。
Scrapy
开发语言：python
Site: http://scrapy.org/
简介

Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。
快速强大：只需编写爬取规则，剩下由scrapy完成
易扩展：扩展性设计，支持插件，无需改动核心代码
可移植性：基于Linux、Windows、Mac、BSD开发和运行
设计

Scrapy架构设计

功能

插件设计，扩展性比较好
爬虫规则定制简单
支持抓取和抽取，数据抽取结构化
抽取支持xpath和css提取网页数据
问题

单机多线程实现，不支持分布式(scrapy-redis为一种分布式实现方案，待调研)
数据存储方案支持 Local filesystem、FTP、S3、Standard output，默认无分布式存储解决方案
默认中间过程网页不会保存，只保存抽取结果
评测
对比

从功能方面来说，Heritrix与Larbin的功能类似。都是一个纯粹的网络爬虫，提供网站的镜像下载。而Nutch是一个网络搜索引擎框架，爬取网页只是其功能的一部分。
从分布式处理来说，Nutch支持分布式处理，而另外两个好像尚且还没有支持。
从爬取的网页存储方式来说，Heritrix和 Larbin都是将爬取下来的内容保存为原始类型的内容。而Nutch是将内容保存到其特定格式的segment中去。
对于爬取下来的内容的处理来说，Heritrix和 Larbin都是将爬取下来的内容不经处理直接保存为原始内容。而Nutch对文本进行了包括链接分析、正文提取、建立索引（Lucene索引）等处理。
从爬取的效率来说，Larbin效率较高，因为其是使用C++实现的并且功能单一。